{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b178e395",
   "metadata": {},
   "source": [
    "# FCM Scoring Walkthrough\n",
    "\n",
    "This notebook demonstrates how to use the FCM scoring utility to compare two Fuzzy Cognitive Maps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584881fb",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Add parent directory to path for imports\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from score_fcms import score_fcm, load_matrix_from_file, matrix_to_json\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cdc151",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5036944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to example files (in same directory)\n",
    "fcm1_path = 'fcm1.csv'\n",
    "fcm2_path = 'fcm2.csv'\n",
    "\n",
    "print(f\"Loading FCM1 from: {fcm1_path}\")\n",
    "print(f\"Loading FCM2 from: {fcm2_path}\")\n",
    "\n",
    "# Load the matrices\n",
    "fcm1_matrix = load_matrix_from_file(fcm1_path)\n",
    "fcm2_matrix = load_matrix_from_file(fcm2_path)\n",
    "\n",
    "print(f\"\\nFCM1 shape: {fcm1_matrix.shape}\")\n",
    "print(f\"FCM2 shape: {fcm2_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a848f6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore FCM1\n",
    "print(\"FCM1 Matrix:\")\n",
    "print(fcm1_matrix)\n",
    "print(f\"\\nNumber of edges: {(fcm1_matrix != 0).sum().sum() // 2}\")\n",
    "print(f\"Number of nodes: {len(fcm1_matrix)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366f93b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore FCM2\n",
    "print(\"FCM2 Matrix:\")\n",
    "print(fcm2_matrix)\n",
    "print(f\"\\nNumber of edges: {(fcm2_matrix != 0).sum().sum() // 2}\")\n",
    "print(f\"Number of nodes: {len(fcm2_matrix)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fca2d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show file information\n",
    "print(f\"FCM1 (CSV Matrix Format):\")\n",
    "print(f\"  - File: {fcm1_path}\")\n",
    "print(f\"  - Format: Adjacency matrix (rows/columns = nodes)\")\n",
    "print(f\"\\nFCM2 (CSV Matrix Format):\")\n",
    "print(f\"  - File: {fcm2_path}\")\n",
    "print(f\"  - Format: Adjacency matrix (rows/columns = nodes)\")\n",
    "print(f\"\\nNote: Both CSV and JSON formats are supported!\")\n",
    "print(f\"  - CSV: Adjacency matrix format\")\n",
    "print(f\"  - JSON: Edge list format with 'edges' array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5693161",
   "metadata": {},
   "source": [
    "## 3. Basic Scoring with Default Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8b4c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score with default parameters\n",
    "print(\"Scoring with default parameters...\\n\")\n",
    "\n",
    "results = score_fcm(\n",
    "    fcm1_path=fcm1_path,\n",
    "    fcm2_path=fcm2_path,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d751c4",
   "metadata": {},
   "source": [
    "## 4. Parameter Tuning: Testing Different Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10320ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different thresholds\n",
    "thresholds = [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "results_list = []\n",
    "\n",
    "print(\"Testing different threshold values...\\n\")\n",
    "\n",
    "for threshold in thresholds:\n",
    "    print(f\"Testing threshold={threshold}...\")\n",
    "    result = score_fcm(\n",
    "        fcm1_path=fcm1_path,\n",
    "        fcm2_path=fcm2_path,\n",
    "        threshold=threshold,\n",
    "        verbose=False\n",
    "    )\n",
    "    results_list.append(result)\n",
    "\n",
    "print(\"Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bf6a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine results and display\n",
    "threshold_results = pd.concat(results_list, ignore_index=True)\n",
    "\n",
    "print(\"\\nScoring Results for Different Thresholds:\")\n",
    "print(\"=\"*80)\n",
    "display_cols = ['threshold', 'F1', 'Jaccard', 'TP', 'PP', 'FP', 'FN']\n",
    "print(threshold_results[display_cols].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3ecb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal threshold\n",
    "best_idx = threshold_results['F1'].idxmax()\n",
    "best_threshold = threshold_results.loc[best_idx, 'threshold']\n",
    "best_f1 = threshold_results.loc[best_idx, 'F1']\n",
    "\n",
    "print(f\"\\nBest F1 Score: {best_f1:.4f}\")\n",
    "print(f\"Achieved at threshold: {best_threshold}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c06cf21",
   "metadata": {},
   "source": [
    "## 5. Interpreting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907c25fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understanding the metrics\n",
    "best_result = results_list[thresholds.index(best_threshold)]\n",
    "\n",
    "tp = int(best_result['TP'].iloc[0])\n",
    "pp = int(best_result['PP'].iloc[0])\n",
    "fp = int(best_result['FP'].iloc[0])\n",
    "fn = int(best_result['FN'].iloc[0])\n",
    "\n",
    "print(\"Understanding the Metrics:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"True Positives (TP):      {tp:3d} - Correct edge matches\")\n",
    "print(f\"Partial Positives (PP):   {pp:3d} - Edge matches with sign disagreement\")\n",
    "print(f\"False Positives (FP):     {fp:3d} - Predicted edges not in reference\")\n",
    "print(f\"False Negatives (FN):     {fn:3d} - Reference edges not predicted\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nF1 Score:     {best_result['F1'].iloc[0]:.4f}\")\n",
    "print(f\"Jaccard Score: {best_result['Jaccard'].iloc[0]:.4f}\")\n",
    "print(f\"\\nF1 = 2*TP / (2*TP + FP + FN)\")\n",
    "print(f\"   = 2*{tp} / (2*{tp} + {fp} + {fn})\")\n",
    "print(f\"   = {2*tp} / {2*tp + fp + fn}\")\n",
    "print(f\"   = {best_result['F1'].iloc[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839a5220",
   "metadata": {},
   "source": [
    "## 6. Saving Results in Different Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cb8aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results in both CSV and JSON formats\n",
    "output_dir = 'results'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Saving results to {output_dir}...\\n\")\n",
    "\n",
    "results_both = score_fcm(\n",
    "    fcm1_path=fcm1_path,\n",
    "    fcm2_path=fcm2_path,\n",
    "    output_dir=output_dir,\n",
    "    output_format='both',\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"Results saved in both CSV and JSON formats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437089c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List saved files\n",
    "import glob\n",
    "\n",
    "print(\"Saved files:\")\n",
    "for filepath in glob.glob(os.path.join(output_dir, '*_scoring_results*')):\n",
    "    filename = os.path.basename(filepath)\n",
    "    file_size = os.path.getsize(filepath)\n",
    "    print(f\"  - {filename} ({file_size} bytes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7b3d46",
   "metadata": {},
   "source": [
    "## 7. Working with Custom FCM Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44c33c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Create a simple custom FCM\n",
    "custom_fcm = pd.DataFrame(\n",
    "    {\n",
    "        'variable_A': [0, 0.8, -0.5],\n",
    "        'variable_B': [0.7, 0, 0.6],\n",
    "        'variable_C': [-0.4, 0.9, 0]\n",
    "    },\n",
    "    index=['variable_A', 'variable_B', 'variable_C']\n",
    ")\n",
    "\n",
    "print(\"Custom FCM:\")\n",
    "print(custom_fcm)\n",
    "\n",
    "# Save it as CSV\n",
    "custom_csv_path = 'custom_fcm.csv'\n",
    "custom_fcm.to_csv(custom_csv_path)\n",
    "print(f\"\\n Saved to {custom_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b2ba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert FCM matrix to JSON format\n",
    "custom_json = matrix_to_json(custom_fcm)\n",
    "\n",
    "print(\"\\nCustom FCM as JSON:\")\n",
    "print(json.dumps(custom_json, indent=2))\n",
    "\n",
    "# Save it as JSON\n",
    "custom_json_path = 'custom_fcm.json'\n",
    "with open(custom_json_path, 'w') as f:\n",
    "    json.dump(custom_json, f, indent=2)\n",
    "print(f\"\\n Saved to {custom_json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e7c0ef",
   "metadata": {},
   "source": [
    "## 8. Comparing FCMs from Two Directories\n",
    "\n",
    "For batch processing, you can compare all FCMs from two directories that have matching filenames using the `compare_fcm_directories` script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835eac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the directory comparison function\n",
    "from compare_fcm_directories import compare_directories, find_matching_files\n",
    "\n",
    "# For this example, let's create two temporary directories with some FCM files\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create test directories\n",
    "test_dir1 = 'test_fcms_set1'\n",
    "test_dir2 = 'test_fcms_set2'\n",
    "\n",
    "os.makedirs(test_dir1, exist_ok=True)\n",
    "os.makedirs(test_dir2, exist_ok=True)\n",
    "\n",
    "# Copy some example files to each directory\n",
    "# (In a real scenario, these directories would already exist with different FCMs)\n",
    "shutil.copy('fcm1.csv', os.path.join(test_dir1, 'sample1.csv'))\n",
    "shutil.copy('fcm2.csv', os.path.join(test_dir2, 'sample1.csv'))\n",
    "\n",
    "print(\"✓ Created test directories with sample FCMs\")\n",
    "print(f\"  {test_dir1}/sample1.csv\")\n",
    "print(f\"  {test_dir2}/sample1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4ada4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, check what matching files were found\n",
    "matches = find_matching_files(test_dir1, test_dir2)\n",
    "print(f\"Found {len(matches)} matching file pair(s):\\n\")\n",
    "for stem, path1, path2 in matches:\n",
    "    print(f\"  {stem}:\")\n",
    "    print(f\"    - {path1}\")\n",
    "    print(f\"    - {path2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb192f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all matching FCMs from the two directories\n",
    "results = compare_directories(\n",
    "    dir1=test_dir1,\n",
    "    dir2=test_dir2,\n",
    "    output_dir='batch_comparison_results',\n",
    "    output_format='both',\n",
    "    threshold=0.5,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"COMPARISON RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(results[['file_pair', 'F1', 'Jaccard', 'TP', 'PP', 'FP', 'FN']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa4da36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the structure of output files\n",
    "print(\"Output structure:\")\n",
    "print(\"\\nbatch_comparison_results/\")\n",
    "for root, dirs, files in os.walk('batch_comparison_results'):\n",
    "    level = root.replace('batch_comparison_results', '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f'{indent}{os.path.basename(root)}/')\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files:\n",
    "        print(f'{subindent}{file}')\n",
    "\n",
    "# Clean up test directories\n",
    "shutil.rmtree(test_dir1)\n",
    "shutil.rmtree(test_dir2)\n",
    "print(f\"\\n✓ Cleaned up test directories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729ad204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compare_fcm_directories import compare_directories, find_matching_files\n",
    "\n",
    "compare_directories(\n",
    "    dir1=\"C:\\\\Users\\\\Nbrug\\\\Desktop\\\\osw-data\",\n",
    "    dir2=\"C:\\\\Users\\\\Nbrug\\\\Desktop\\\\iea_adjacency_matrices_AI\",\n",
    "    output_dir='C:\\\\Users\\\\Nbrug\\\\Desktop\\\\iea_results',\n",
    "    output_format='both',\n",
    "    threshold=0.5,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66bddbd",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "This walkthrough demonstrated:\n",
    "\n",
    "1. **Loading FCM data** in both CSV and JSON formats\n",
    "2. **Basic scoring** with default parameters\n",
    "3. **Parameter tuning** by testing different thresholds\n",
    "4. **Result interpretation** - understanding TP, PP, FP, FN metrics\n",
    "5. **Flexible output** - saving results in CSV and/or JSON\n",
    "6. **Format conversion** - working with custom FCM data\n",
    "7. **Batch processing** - comparing multiple FCM pairs from two directories\n",
    "\n",
    "### Key Takeaways:\n",
    "- **Threshold tuning** is important for getting good results\n",
    "- **F1 and Jaccard scores** provide different perspectives on matching quality\n",
    "- **Edge counts matter** - more edges can lead to more false positives\n",
    "- **Flexible I/O** - use CSV for matrices, JSON for edge lists\n",
    "- **Batch comparison** - efficiently process multiple FCM pairs with matching filenames"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scorefcm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
